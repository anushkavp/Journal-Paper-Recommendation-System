{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import urllib.request\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime\n",
    "from rake_nltk import Rake\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arxivData.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_month = { 1:'Jan',2:'Feb', 3:'Mar', 4:'Apr',5:'May', 6:\"Jun\",7:'Jul',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'}\n",
    "con_day = { 1:'01',2:'02',3:'03',4:'04',5:'05',6:'06',7:'07',8:'08',9:'09'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    if i['month'] in con_month:\n",
    "        i['month'] = con_month[i['month']]\n",
    "    if i['day'] in con_day:\n",
    "        i['day'] = con_day[i['day']]\n",
    "    else: \n",
    "        i['day'] = str(i['day'])\n",
    "    i['year'] = str(i['year'])\n",
    "\n",
    "for i in data:\n",
    "    date = i['day']+'-'+i['month']+'-'+i['year']\n",
    "    #print(\"DATE=\",date)\n",
    "    k = datetime.strptime(date,'%d-%b-%Y')\n",
    "    i['date'] = datetime.timestamp(k)\n",
    "    del i['day'], i['month'],i['year']\n",
    "    \n",
    "for i in data:\n",
    "    i['summary'] = i['summary'].replace('\\n',' ')\n",
    "    i['title'] = i['title'].replace('\\n',' ')\n",
    "    del i['id'],i['link'],i['tag'] #irrelevant for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema\n"
     ]
    }
   ],
   "source": [
    "term = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = []\n",
    "for i in data:\n",
    "    if term in i['title'] or term in i['summary']:\n",
    "        papers.append(i)\n",
    "        \n",
    "#sort according to date\n",
    "papers = sorted(papers, key = lambda i:i['date'])\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take top 5 and bottom 5\n",
    "final_summary = []\n",
    "if len(papers)>10:\n",
    "    final_list = papers[:5] + papers[-5:]\n",
    "else:\n",
    "    final_list = papers\n",
    "for i in final_list:\n",
    "    final_summary.append(i['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes punctuation\n",
    "#re.sub is used for replacing strings\n",
    "def pre_process(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(\"&lt;/?.*?&gt;\",\"&lt;&gt\",text)\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary and word counts\n",
    "\n",
    "def get_stop(fpath):\n",
    "    \n",
    "    with open(fpath,\"r\",encoding = \"utf-8\") as f:\n",
    "        stopw = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopw)\n",
    "        return frozenset(stop_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples,key=lambda x:(x[1],x[0]),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(fnames,sitems,topn=0):\n",
    "    sitems = sitems[:topn]\n",
    "    scoreval = []\n",
    "    featureval = []\n",
    "    \n",
    "    for idx, score in sitems:\n",
    "        scoreval.append(round(score,3))\n",
    "        featureval.append(fnames[idx])\n",
    "        \n",
    "    results = {}\n",
    "    \n",
    "    for idx in range(len(featureval)):\n",
    "        results[featureval[idx]] = scoreval[idx]\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_list:\n",
    "    i['summary'] = pre_process(i['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stopwords = get_stop('stopwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['herse', 'himse', 'itse', 'myse'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cv = CountVectorizer(max_df = 0.85,stop_words = stopwords,max_features=10000)\n",
    "    word_cv = cv.fit_transform(docs)\n",
    "    #print(word_cv)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tt.fit(word_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    "#feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text_key = []\n",
    "for doc in docs:\n",
    "    tvector = tt.transform(cv.transform([doc]))\n",
    "    sitems = sort_coo(tvector.tocoo())\n",
    "    #print(sitems)\n",
    "    keywords = extraction(feature_names,sitems,10)\n",
    "    #print(keywords)\n",
    "    text_key = {\n",
    "        'summary':pre_process(doc),\n",
    "        'keywords':list(keywords.keys())\n",
    "    }\n",
    "    final_text_key.append(text_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_text_key[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_list:\n",
    "    for j in final_text_key:\n",
    "        if j['summary']==i['summary']:\n",
    "            i['keywords']=j['keywords']\n",
    "            del i['summary']\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': \"[{'name': 'Neil Dhir'}, {'name': 'Houman Dallali'}, {'name': 'Mo Rastgaar'}]\",\n",
       " 'title': 'Coregionalised Locomotion Envelopes - A Qualitative Approach',\n",
       " 'date': 1520879400.0,\n",
       " 'keywords': ['new',\n",
       "  'signals',\n",
       "  'sensors',\n",
       "  'locomotion',\n",
       "  'control',\n",
       "  'exploit',\n",
       "  'method',\n",
       "  'learning',\n",
       "  'walking',\n",
       "  'variates']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = term+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cit(title):\n",
    "        dat = requests.get('https://scholar.google.com/scholar?q='+title, headers = {'User-agent': 'your bot 0.1'})\n",
    "        #requests.get(link, headers = {'User-agent': 'your bot 0.1'})\n",
    "        dat.raise_for_status()\n",
    "        soup = bs(dat.text,\"html.parser\")\n",
    "        res_link = soup.select(\".gs_rt a\")\n",
    "        for i in res_link:\n",
    "            print(i.text)\n",
    "            print(i['href'])\n",
    "            break\n",
    "        cit_link = soup.select(\".gs_fl a\")\n",
    "        for i in cit_link:\n",
    "                if \"Cited by\" in i.text:\n",
    "                    print(int(i.text[9:]))\n",
    "                    return int(i.text[9:])\n",
    "                    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntactic-head-driven generation\n",
      "https://dl.acm.org/citation.cfm?id=991969\n",
      "11\n",
      "An implemented model of punning riddles\n",
      "https://www.aaai.org/Papers/AAAI/1994/AAAI94-096.pdf\n",
      "107\n",
      "Operations for learning with graphical models\n",
      "http://www.jair.org/papers/paper62.html\n",
      "769\n",
      "Genetic algorithms in time-dependent environments\n",
      "https://link.springer.com/chapter/10.1007/978-3-662-04448-3_13\n",
      "51\n",
      "Reasoning with individuals for the description logic\n",
      "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.7645&rep=rep1&type=pdf\n",
      "3\n",
      "MRI tumor segmentation with densely connected 3D CNN\n",
      "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10574/105741F/MRI-tumor-segmentation-with-densely-connected-3D-CNN/10.1117/12.2293394.short\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "with open(f,\"w\") as file:\n",
    "    fwriter = csv.writer(file)\n",
    "    fwriter.writerow([\"author\",\"title\",\"date\",\"keywords\",\"citation\"])\n",
    "    for i in final_list: \n",
    "        fwriter.writerow([i['author'],i['title'],i['date'],i['keywords'],get_cit(i['title'])]) \n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=\"schema.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>keywords</th>\n",
       "      <th>citation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[{'name': 'Esther Koenig'}]</td>\n",
       "      <td>Syntactic-Head-Driven Generation</td>\n",
       "      <td>767903400.0</td>\n",
       "      <td>['head', 'semantic', 'syntactic', 'driven', 'g...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[{'name': 'Kim Binsted'}, {'name': 'Graeme Rit...</td>\n",
       "      <td>An implemented model of punning riddles</td>\n",
       "      <td>771445800.0</td>\n",
       "      <td>['jokes', 'joke', 'jape', 'model', 'words', 'u...</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[{'name': 'W. L. Buntine'}]</td>\n",
       "      <td>Operations for Learning with Graphical Models</td>\n",
       "      <td>786220200.0</td>\n",
       "      <td>['graphical', 'learning', 'models', 'framework...</td>\n",
       "      <td>769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[{'name': 'Christopher Ronnewinkel'}, {'name':...</td>\n",
       "      <td>Genetic Algorithms in Time-Dependent Environments</td>\n",
       "      <td>941653800.0</td>\n",
       "      <td>['rate', 'population', 'phase', 'mutation', 'g...</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[{'name': 'Ian Horrock'}, {'name': 'Ulrike Sat...</td>\n",
       "      <td>Reasoning with Individuals for the Description...</td>\n",
       "      <td>957983400.0</td>\n",
       "      <td>['tbox', 'reasoning', 'implementation', 'algor...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              author  \\\n",
       "0                        [{'name': 'Esther Koenig'}]   \n",
       "1  [{'name': 'Kim Binsted'}, {'name': 'Graeme Rit...   \n",
       "2                        [{'name': 'W. L. Buntine'}]   \n",
       "3  [{'name': 'Christopher Ronnewinkel'}, {'name':...   \n",
       "4  [{'name': 'Ian Horrock'}, {'name': 'Ulrike Sat...   \n",
       "\n",
       "                                               title         date  \\\n",
       "0                   Syntactic-Head-Driven Generation  767903400.0   \n",
       "1            An implemented model of punning riddles  771445800.0   \n",
       "2      Operations for Learning with Graphical Models  786220200.0   \n",
       "3  Genetic Algorithms in Time-Dependent Environments  941653800.0   \n",
       "4  Reasoning with Individuals for the Description...  957983400.0   \n",
       "\n",
       "                                            keywords  citation  \n",
       "0  ['head', 'semantic', 'syntactic', 'driven', 'g...      11.0  \n",
       "1  ['jokes', 'joke', 'jape', 'model', 'words', 'u...     107.0  \n",
       "2  ['graphical', 'learning', 'models', 'framework...     769.0  \n",
       "3  ['rate', 'population', 'phase', 'mutation', 'g...      51.0  \n",
       "4  ['tbox', 'reasoning', 'implementation', 'algor...       3.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(f,encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(['citation','date'],ascending=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operations for Learning with Graphical Models'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest = df.iloc[0]['title']\n",
    "highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>An implemented model of punning riddles</th>\n",
       "      <th>Genetic Algorithms in Time-Dependent Environments</th>\n",
       "      <th>MRI Tumor Segmentation with Densely Connected 3D CNN</th>\n",
       "      <th>Operations for Learning with Graphical Models</th>\n",
       "      <th>Reasoning with Individuals for the Description Logic SHIQ</th>\n",
       "      <th>Syntactic-Head-Driven Generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>citation</td>\n",
       "      <td>107.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>769.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "title     An implemented model of punning riddles  \\\n",
       "citation                                    107.0   \n",
       "\n",
       "title     Genetic Algorithms in Time-Dependent Environments  \\\n",
       "citation                                               51.0   \n",
       "\n",
       "title     MRI Tumor Segmentation with Densely Connected 3D CNN  \\\n",
       "citation                                               26.0      \n",
       "\n",
       "title     Operations for Learning with Graphical Models  \\\n",
       "citation                                          769.0   \n",
       "\n",
       "title     Reasoning with Individuals for the Description Logic SHIQ  \\\n",
       "citation                                                3.0           \n",
       "\n",
       "title     Syntactic-Head-Driven Generation  \n",
       "citation                              11.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_mat = df.pivot_table(columns='title',values='citation')\n",
    "paper_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citation    769.0\n",
       "Name: Operations for Learning with Graphical Models, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cit=paper_mat[highest]\n",
    "high_cit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2522: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2451: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "title\n",
       "An implemented model of punning riddles                     NaN\n",
       "Genetic Algorithms in Time-Dependent Environments           NaN\n",
       "MRI Tumor Segmentation with Densely Connected 3D CNN        NaN\n",
       "Operations for Learning with Graphical Models               NaN\n",
       "Reasoning with Individuals for the Description Logic SHIQ   NaN\n",
       "Syntactic-Head-Driven Generation                            NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim2high=paper_mat.corrwith(high_cit,axis=0)\n",
    "sim2high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['head', 'semantic', 'syntactic', 'driven', 'g...\n",
       "1    ['jokes', 'joke', 'jape', 'model', 'words', 'u...\n",
       "2    ['graphical', 'learning', 'models', 'framework...\n",
       "3    ['rate', 'population', 'phase', 'mutation', 'g...\n",
       "4    ['tbox', 'reasoning', 'implementation', 'algor...\n",
       "5    ['tumor', 'gliomas', 'enhancing', '3d', 'model...\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(f, encoding='latin-1')\n",
    "df=df.dropna()\n",
    "#for i in df['keywords']:\n",
    "#    i=((\" \".join(((i[1:len(i)-2]).split(\",\")))))\n",
    "df['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0.  0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0.1]\n",
      " [0.  0.  1.  0.  0.  0. ]\n",
      " [0.  0.  0.  1.  0.  0. ]\n",
      " [0.  0.  0.  0.  1.  0. ]\n",
      " [0.  0.1 0.  0.  0.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "# instantiating and generating the count matrix\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(df['keywords'])\n",
    "\n",
    "# generating the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
